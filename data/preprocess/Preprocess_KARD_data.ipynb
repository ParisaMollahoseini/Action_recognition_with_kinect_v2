{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ Put skeleton data file names to an array named files_in_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files_in_folder = []\n",
    "data_path = \"E:/my_courses/project/kinect dataset\"\n",
    "for file in os.listdir(data_path):\n",
    "    if file.endswith(\"_screen.txt\"):\n",
    "        print(os.path.join(data_path, file))\n",
    "        files_in_folder.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_in_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Get the number of frames in each file in files_in_folder and put it in frames_file array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:/my_courses/project/kinect dataset/\"\n",
    "frames_file = []\n",
    "for i in files_in_folder:\n",
    "    with open(path+i) as f:\n",
    "        frames_file.append(len(f.readlines())/15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Calculate minimum frame number among files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(frames_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ See number of frames per second some files have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04132231404958678"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.390243902439025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038834951456310676"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.315789473684212"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.038"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.041666666666666664"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.390243902439025"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.041"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0392156862745098"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.641025641025642"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.039603960396039604"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.641025641025642"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.039"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04032258064516129"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.037383177570093455"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4/107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.027027027027028"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040983606557377046"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5/122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/0.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.5"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.5/0.04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Finally 42 is good for windows size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Move files to test and train folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "test_counter = 0\n",
    "path = \"E:/my_courses/project/kinect dataset/\"\n",
    "path_to_copy = \"E:/my_courses/project/final_files/dataset/\"\n",
    "for i in range(len(files_in_folder)):\n",
    "    if i == test_counter:\n",
    "        shutil.copy(path+files_in_folder[i], path_to_copy+\"test\")\n",
    "        test_counter += 12\n",
    "    else:\n",
    "        shutil.copy(path+files_in_folder[i], path_to_copy+\"train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ 8 percent test data = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Remove some frames from each file (train or test) to reach 42 frames\n",
    "##       Then move them to new folders. (train_2 or val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "path = \"E:/my_courses/project/final_files/dataset/train/\" #train  or test\n",
    "path_save = \"E:/my_courses/project/final_files/dataset/train_2/\" #train_2  or val \n",
    "\n",
    "files_in_folder = []\n",
    "for file in os.listdir(path):\n",
    "    files_in_folder.append(file)\n",
    "    \n",
    "frames_file = []\n",
    "\n",
    "for j in files_in_folder:\n",
    "    with open(path+j) as f:\n",
    "        \n",
    "        for line in f.readlines():\n",
    "            frames_file.append([int(float(x)) for x in (line.split())])  \n",
    "            \n",
    "        len_frames = int(len(frames_file)/15)\n",
    "        print('len_1: ',len_frames)\n",
    "        if len_frames >= 100: #remove first 25 and last 12 frames\n",
    "            len_frames -= 37\n",
    "            frames_file = frames_file[25*15:-12*15]\n",
    "            print('len_frames: ',len_frames)\n",
    "            \n",
    "        num = int(len_frames/42)*42 \n",
    "        part_forward = (num/(42-(len_frames - num)))\n",
    "        rest = (len_frames - num)\n",
    "        \n",
    "        final_file = []\n",
    "        \n",
    "\n",
    "        counter = 15 \n",
    "        print(j)\n",
    "        i = 0 \n",
    "        o = 0\n",
    "        condition = False\n",
    "        \n",
    "        while True:\n",
    "            round_i = round(i)\n",
    "            \n",
    "            final_file.append(frames_file[round_i*counter:(round_i+1)*counter])\n",
    "            i += part_forward\n",
    "                 \n",
    "            o += 1\n",
    "            if condition == True:\n",
    "                break\n",
    "                \n",
    "            if condition == False and o == (42-(len_frames - num)):\n",
    "                if  ((num) - (i-part_forward))<10:\n",
    "                    break\n",
    "                else:\n",
    "                    condition = True\n",
    "\n",
    "                \n",
    "        if condition:  \n",
    "            print('--')\n",
    "            num += 1\n",
    "        \n",
    "        for s in range(num,len_frames):\n",
    "            final_file.append(frames_file[s*counter:(s+1)*counter])    \n",
    "        \n",
    "        print('diff: ',(num) - (i-part_forward))\n",
    "        print(o + len_frames-num)\n",
    "        \n",
    "        #save to file\n",
    "        train_file = open(path_save+j, \"w\")\n",
    "        for row in final_file:\n",
    "            np.savetxt(train_file, row)\n",
    "        train_file.close()\n",
    "        frames_file = []\n",
    "        print('---------------------end-------------------------')\n",
    "        #save to file\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ For whatching selected frames of specified file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "path_save = \"E:/my_courses/project/final_files/dataset/train_2/\" \n",
    "import numpy as np \n",
    "import cv2\n",
    "img = np.zeros((640,480))\n",
    "with open(path_save+'a13_s01_e03_screen.txt') as f:\n",
    "    \n",
    "    c = 0\n",
    "    k = 0\n",
    "    print('yes')\n",
    "    for line in f.readlines():\n",
    "        \n",
    "        seq_lines = ([int(float(x)) for x in (line.split())])\n",
    "        img = cv2.circle(img,(seq_lines[0],seq_lines[1]),10,255,-1) \n",
    "        c += 1\n",
    "        if c % 15 == 0:\n",
    "            cv2.imwrite(path_save+'{}.jpg'.format(c),img)\n",
    "            img = np.zeros((640,480))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Convert skeleton data to image by keeping the label as name of image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization:\n",
    "255*(x_i-min⁡(X))/(max⁡(X)-min⁡(X) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head = 3  \n",
    "# Neck = 2  \n",
    "# Right_Shoulder = 8\n",
    "# Right_Elbow = 9\n",
    "# Right_Hand = 11\n",
    "# Left_Shoulder = 4\n",
    "# Left_Elbow = 5\n",
    "# Left_Hand = 7\n",
    "# Torso = 1\n",
    "# Right_Hip = 16\n",
    "# Right_Knee = 17\n",
    "# Right_Foot = 19 \n",
    "# Left_Hip = 12\n",
    "# Left_Knee = 13\n",
    "# Left_Foot = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_2_path = \"E:/my_courses/project/final_files/dataset/val/\"#val,train_2,test\n",
    "save_img_path = \"E:/my_courses/project/final_files/dataset/val_dist_scale/\"#train_dist_scale,val_dist_scale,test_dist_scale\n",
    "\n",
    "\n",
    "for file in os.listdir(train_2_path):\n",
    "    with open(train_2_path+file) as f:\n",
    "        seq_lines = []\n",
    "\n",
    "        label = file.split('.')[0][:-7]\n",
    "        \n",
    "        for line in f.readlines():\n",
    "            seq_lines.append(([int(float(x)) for x in (line.split())]))\n",
    "        \n",
    "        seq_lines = np.array(seq_lines)\n",
    "        X = seq_lines[:,0]\n",
    "        Y = seq_lines[:,1]\n",
    "        Z = seq_lines[:,2]\n",
    "        \n",
    "        X = X.reshape(X.reshape(15,-1).shape[1],15).transpose()\n",
    "        X = X[8] - X # DISTANCE between torso and others\n",
    "        X = np.delete(X, 1, 0) #delete torso \n",
    "        \n",
    "        Z = Z.reshape(Z.reshape(15,-1).shape[1],15).transpose()\n",
    "        div = np.delete(Z, 1, 0)\n",
    "        \n",
    "        X = X * (div/4500) # scale every points to 4.5 meter distance of kinect camera\n",
    "        r = (255*(X-(X.min()))/((X.max())-(X.min()))).astype(int) # Normalization and put into to 0-255 range\n",
    "        \n",
    "        Y = Y.reshape(Y.reshape(15,-1).shape[1],15).transpose()\n",
    "        Y = Y[8] - Y\n",
    "        Y = np.delete(Y, 1, 0) #delete torso\n",
    "        Y = Y * (div/4500)\n",
    "        g = (255*(Y-(Y.min()))/((Y.max())-(Y.min()))).astype(int)\n",
    "        \n",
    "        Z = Z[8] - Z  \n",
    "        Z = np.delete(Z, 1, 0) #delete torso\n",
    "        b = (255*(Z-(Z.min()))/((Z.max())-(Z.min()))).astype(int)\n",
    "        \n",
    "        image = cv2.merge((r,g,b))\n",
    "        cv2.imwrite(save_img_path+label+\".jpg\",image)        \n",
    "         \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
