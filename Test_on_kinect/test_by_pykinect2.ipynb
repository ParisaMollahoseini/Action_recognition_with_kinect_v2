{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/pytorch/tnt.git@master\n",
      "  Cloning https://github.com/pytorch/tnt.git (to revision master) to c:\\users\\soheil~1\\appdata\\local\\temp\\pip-req-build-l80p5668\n",
      "Requirement already satisfied (use --upgrade to upgrade): torchnet==0.0.5.1 from git+https://github.com/pytorch/tnt.git@master in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages\n",
      "Requirement already satisfied: torch in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchnet==0.0.5.1) (1.10.2)\n",
      "Requirement already satisfied: six in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchnet==0.0.5.1) (1.16.0)\n",
      "Requirement already satisfied: future in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchnet==0.0.5.1) (0.18.2)\n",
      "Requirement already satisfied: visdom in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchnet==0.0.5.1) (0.1.8.9)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torch->torchnet==0.0.5.1) (4.0.1)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torch->torchnet==0.0.5.1) (0.8)\n",
      "Requirement already satisfied: websocket-client in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (1.2.3)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (2.22.0)\n",
      "Requirement already satisfied: pyzmq in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (18.1.1)\n",
      "Requirement already satisfied: scipy in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.8 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (1.19.5)\n",
      "Requirement already satisfied: jsonpatch in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (1.32)\n",
      "Requirement already satisfied: tornado in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (6.0.3)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (7.0.0)\n",
      "Requirement already satisfied: torchfile in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from visdom->torchnet==0.0.5.1) (0.1.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests->visdom->torchnet==0.0.5.1) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests->visdom->torchnet==0.0.5.1) (1.25.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests->visdom->torchnet==0.0.5.1) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from requests->visdom->torchnet==0.0.5.1) (2019.11.28)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from jsonpatch->visdom->torchnet==0.0.5.1) (2.2)\n",
      "Building wheels for collected packages: torchnet\n",
      "  Building wheel for torchnet (setup.py): started\n",
      "  Building wheel for torchnet (setup.py): finished with status 'done'\n",
      "  Created wheel for torchnet: filename=torchnet-0.0.5.1-py3-none-any.whl size=31207 sha256=5f62040f6f6884a1b4e0d723d05758cb52a869fb45532f9f5a990b1779d77226\n",
      "  Stored in directory: C:\\Users\\SOHEIL~1\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-z7q9xskg\\wheels\\e1\\d4\\7a\\e9a5ec0d0dcd304bfa84d2cbb8a7507a5e728ce154981dc87d\n",
      "Successfully built torchnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/pytorch/tnt.git 'C:\\Users\\SOHEIL~1\\AppData\\Local\\Temp\\pip-req-build-l80p5668'\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/pytorch/tnt.git@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: numpy in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchvision) (7.0.0)\n",
      "Requirement already satisfied: torch==1.10.2 in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torchvision) (1.10.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torch==1.10.2->torchvision) (0.8)\n",
      "Requirement already satisfied: typing-extensions in e:\\anaconda\\envs\\tensorflow\\lib\\site-packages (from torch==1.10.2->torchvision) (4.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "save_img_path = \"E:/my_courses/project/pykinect2/PyKinect2/examples/body_skeleton_images/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_to_image(body_seq,index1,index2):#gets array with len 42 and each element is array of size 15 \n",
    "        \n",
    "        seq_lines = np.array(body_seq)\n",
    "        X = np.array(seq_lines[:,:,0])\n",
    "        Y = np.array(seq_lines[:,:,1])\n",
    "        Z = np.array(seq_lines[:,:,2])\n",
    "\n",
    "        r = (255*(X-(X.min()))/(X.max()-X.min())).astype(int).reshape(15,-1)\n",
    "        g = (255*(Y-Y.min())/(Y.max()-Y.min())).astype(int).reshape(15,-1)\n",
    "        b = (255*(Z-Z.min())/(Z.max()-Z.min())).astype(int).reshape(15,-1)\n",
    "        \n",
    "        image = cv2.merge((r,g,b))\n",
    "#         img_name = save_img_path+str(index1)+str(index2)+\".jpg\"\n",
    "#         cv2.imwrite(img_name,image)\n",
    "        print('body to image',image.shape)\n",
    "        return image\n",
    "        #print(img_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Bend', 'Hand Clap', 'Walk', 'Sit down', 'Stand up']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=5, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'E:/my_courses/project/final_files/model/'\n",
    "model=torch.load(model_path+'Mymodel_003.pth',map_location=torch.device('cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(img):\n",
    "#     to_pil = transforms.ToPILImage()\n",
    "#     image = to_pil(img)\n",
    "    image = Image.fromarray(img.astype('uint8'), 'RGB')\n",
    "    test_transforms = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                     ])\n",
    "    image_tensor = test_transforms(image).float()\n",
    "    image_tensor = image_tensor.unsqueeze_(0)\n",
    "    input1 = Variable(image_tensor)\n",
    "    input1 = input1.to('cpu')\n",
    "    output = model(input1)\n",
    "    index = output.data.cpu().numpy().argmax()\n",
    "    \n",
    "    return str(classes[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body size: 1\n",
      "Body size: 2\n",
      "Body size: 3\n",
      "Body size: 4\n",
      "Body size: 5\n",
      "Body size: 6\n",
      "Body size: 7\n",
      "Body size: 8\n",
      "Body size: 9\n",
      "Body size: 10\n",
      "Body size: 11\n",
      "Body size: 12\n",
      "Body size: 13\n",
      "Body size: 14\n",
      "Body size: 15\n",
      "Body size: 16\n",
      "Body size: 17\n",
      "Body size: 18\n",
      "Body size: 19\n",
      "Body size: 20\n",
      "Body size: 21\n",
      "Body size: 22\n",
      "Body size: 23\n",
      "Body size: 24\n",
      "Body size: 25\n",
      "Body size: 26\n",
      "Body size: 27\n",
      "Body size: 28\n",
      "Body size: 29\n",
      "Body size: 30\n",
      "Body size: 31\n",
      "Body size: 32\n",
      "Body size: 33\n",
      "Body size: 34\n",
      "Body size: 35\n",
      "Body size: 36\n",
      "Body size: 37\n",
      "Body size: 38\n",
      "Body size: 39\n",
      "Body size: 40\n",
      "Body size: 41\n",
      "Body size: 42\n",
      "body to image (15, 42, 3)\n",
      "Body size: 43\n",
      "body to image (15, 42, 3)\n",
      "Body size: 44\n",
      "body to image (15, 42, 3)\n",
      "Body size: 45\n",
      "body to image (15, 42, 3)\n",
      "Body size: 46\n",
      "body to image (15, 42, 3)\n",
      "Body size: 47\n",
      "body to image (15, 42, 3)\n",
      "Body size: 48\n",
      "body to image (15, 42, 3)\n",
      "Body size: 49\n",
      "body to image (15, 42, 3)\n",
      "Body size: 50\n",
      "body to image (15, 42, 3)\n",
      "Body size: 51\n",
      "body to image (15, 42, 3)\n",
      "Body size: 52\n",
      "body to image (15, 42, 3)\n",
      "Body size: 53\n",
      "body to image (15, 42, 3)\n",
      "Body size: 54\n",
      "body to image (15, 42, 3)\n",
      "Body size: 55\n",
      "body to image (15, 42, 3)\n",
      "Body size: 56\n",
      "body to image (15, 42, 3)\n",
      "Body size: 57\n",
      "body to image (15, 42, 3)\n",
      "Body size: 58\n",
      "body to image (15, 42, 3)\n",
      "Body size: 59\n",
      "body to image (15, 42, 3)\n",
      "Body size: 60\n",
      "body to image (15, 42, 3)\n",
      "Body size: 61\n",
      "body to image (15, 42, 3)\n",
      "Body size: 62\n",
      "body to image (15, 42, 3)\n",
      "Body size: 63\n",
      "body to image (15, 42, 3)\n",
      "Body size: 64\n",
      "body to image (15, 42, 3)\n",
      "Body size: 65\n",
      "body to image (15, 42, 3)\n",
      "Body size: 66\n",
      "body to image (15, 42, 3)\n",
      "Body size: 67\n",
      "body to image (15, 42, 3)\n",
      "Body size: 68\n",
      "body to image (15, 42, 3)\n",
      "Body size: 69\n",
      "body to image (15, 42, 3)\n",
      "Body size: 70\n",
      "body to image (15, 42, 3)\n",
      "Body size: 71\n",
      "body to image (15, 42, 3)\n",
      "Body size: 72\n",
      "body to image (15, 42, 3)\n",
      "Body size: 73\n",
      "body to image (15, 42, 3)\n",
      "Body size: 74\n",
      "body to image (15, 42, 3)\n",
      "Body size: 75\n",
      "body to image (15, 42, 3)\n",
      "Body size: 76\n",
      "body to image (15, 42, 3)\n",
      "Body size: 77\n",
      "body to image (15, 42, 3)\n",
      "Body size: 78\n",
      "body to image (15, 42, 3)\n",
      "Body size: 79\n",
      "body to image (15, 42, 3)\n",
      "Body size: 80\n",
      "body to image (15, 42, 3)\n",
      "Body size: 81\n",
      "body to image (15, 42, 3)\n",
      "Body size: 82\n",
      "body to image (15, 42, 3)\n",
      "Body size: 83\n",
      "body to image (15, 42, 3)\n",
      "Body size: 84\n",
      "body to image (15, 42, 3)\n",
      "Body size: 85\n",
      "body to image (15, 42, 3)\n",
      "Body size: 86\n",
      "body to image (15, 42, 3)\n",
      "Body size: 87\n",
      "body to image (15, 42, 3)\n",
      "Body size: 88\n",
      "body to image (15, 42, 3)\n",
      "Body size: 89\n",
      "body to image (15, 42, 3)\n",
      "Body size: 90\n",
      "body to image (15, 42, 3)\n",
      "Body size: 91\n",
      "body to image (15, 42, 3)\n",
      "Body size: 92\n",
      "body to image (15, 42, 3)\n",
      "Body size: 93\n",
      "body to image (15, 42, 3)\n",
      "Body size: 94\n",
      "body to image (15, 42, 3)\n",
      "Body size: 95\n",
      "body to image (15, 42, 3)\n",
      "Body size: 96\n",
      "body to image (15, 42, 3)\n",
      "Body size: 97\n",
      "body to image (15, 42, 3)\n",
      "Body size: 98\n",
      "body to image (15, 42, 3)\n",
      "Body size: 99\n",
      "body to image (15, 42, 3)\n",
      "Body size: 100\n",
      "body to image (15, 42, 3)\n",
      "Body size: 101\n",
      "body to image (15, 42, 3)\n",
      "Body size: 102\n",
      "body to image (15, 42, 3)\n",
      "Body size: 103\n",
      "body to image (15, 42, 3)\n",
      "Body size: 104\n",
      "body to image (15, 42, 3)\n",
      "Body size: 105\n",
      "body to image (15, 42, 3)\n",
      "Body size: 106\n",
      "body to image (15, 42, 3)\n",
      "Body size: 107\n",
      "body to image (15, 42, 3)\n",
      "Body size: 108\n",
      "body to image (15, 42, 3)\n",
      "Body size: 109\n",
      "body to image (15, 42, 3)\n",
      "Body size: 110\n",
      "body to image (15, 42, 3)\n",
      "Body size: 111\n",
      "body to image (15, 42, 3)\n",
      "Body size: 112\n",
      "body to image (15, 42, 3)\n",
      "Body size: 113\n",
      "body to image (15, 42, 3)\n",
      "Body size: 114\n",
      "body to image (15, 42, 3)\n",
      "Body size: 115\n",
      "body to image (15, 42, 3)\n",
      "Body size: 116\n",
      "body to image (15, 42, 3)\n",
      "Body size: 117\n",
      "body to image (15, 42, 3)\n",
      "Body size: 118\n",
      "body to image (15, 42, 3)\n",
      "Body size: 119\n",
      "body to image (15, 42, 3)\n",
      "Body size: 120\n",
      "body to image (15, 42, 3)\n",
      "Body size: 121\n",
      "body to image (15, 42, 3)\n",
      "Body size: 122\n",
      "body to image (15, 42, 3)\n",
      "Body size: 123\n",
      "body to image (15, 42, 3)\n",
      "Body size: 124\n",
      "body to image (15, 42, 3)\n",
      "Body size: 125\n",
      "body to image (15, 42, 3)\n",
      "Body size: 126\n",
      "body to image (15, 42, 3)\n",
      "Body size: 127\n",
      "body to image (15, 42, 3)\n",
      "Body size: 128\n",
      "body to image (15, 42, 3)\n",
      "Body size: 129\n",
      "body to image (15, 42, 3)\n",
      "Body size: 130\n",
      "body to image (15, 42, 3)\n",
      "Body size: 131\n",
      "body to image (15, 42, 3)\n",
      "Body size: 132\n",
      "body to image (15, 42, 3)\n",
      "Body size: 133\n",
      "body to image (15, 42, 3)\n",
      "Body size: 134\n",
      "body to image (15, 42, 3)\n",
      "Body size: 135\n",
      "body to image (15, 42, 3)\n",
      "Body size: 136\n",
      "body to image (15, 42, 3)\n",
      "Body size: 137\n",
      "body to image (15, 42, 3)\n",
      "Body size: 138\n",
      "body to image (15, 42, 3)\n",
      "Body size: 139\n",
      "body to image (15, 42, 3)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 228449 is out of bounds for axis 0 with size 217088",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-dfc392b74861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[0m__main__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Kinect v2 Body Game\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[0mgame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBodyGameRuntime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m \u001b[0mgame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-dfc392b74861>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjoint_points\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSKELETON_COLORS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-dfc392b74861>\u001b[0m in \u001b[0;36mdraw_body\u001b[1;34m(self, joints, jointPoints, color)\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_body_bone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjointPoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_SpineShoulder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_ShoulderRight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_body_bone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjointPoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_SpineShoulder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_ShoulderLeft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_body_bone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjointPoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_SpineBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_HipRight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_body_bone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjointPoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_SpineBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_HipLeft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-dfc392b74861>\u001b[0m in \u001b[0;36mdraw_body_bone\u001b[1;34m(self, joints, jointPoints, color, joint0, joint1)\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_depth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjoint1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoint_depth\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjoint1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_depth\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m512\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m## Its in Millimeters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOne_frame_points\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mjoint1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mjoint1\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPyKinectV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJointType_FootLeft\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 228449 is out of bounds for axis 0 with size 217088"
     ]
    }
   ],
   "source": [
    "from pykinect2 import PyKinectV2\n",
    "from pykinect2.PyKinectV2 import *\n",
    "from pykinect2 import PyKinectRuntime\n",
    "import numpy as np \n",
    "import ctypes\n",
    "import _ctypes\n",
    "import pygame\n",
    "import sys\n",
    "\n",
    "if sys.hexversion >= 0x03000000:\n",
    "    import _thread as thread\n",
    "else:\n",
    "    import thread\n",
    "\n",
    "# colors for drawing different bodies \n",
    "SKELETON_COLORS = [pygame.color.THECOLORS[\"red\"], \n",
    "                  pygame.color.THECOLORS[\"blue\"], \n",
    "                  pygame.color.THECOLORS[\"green\"], \n",
    "                  pygame.color.THECOLORS[\"orange\"], \n",
    "                  pygame.color.THECOLORS[\"purple\"], \n",
    "                  pygame.color.THECOLORS[\"yellow\"], \n",
    "                  pygame.color.THECOLORS[\"violet\"]]\n",
    "\n",
    "\n",
    "class BodyGameRuntime(object):\n",
    "    def __init__(self):\n",
    "        pygame.init()\n",
    "\n",
    "        # Used to manage how fast the screen updates\n",
    "        self._clock = pygame.time.Clock()\n",
    "\n",
    "        # Set the width and height of the screen [width, height]\n",
    "        self._infoObject = pygame.display.Info()\n",
    "        self._screen = pygame.display.set_mode((self._infoObject.current_w >> 1, self._infoObject.current_h >> 1), \n",
    "                                               pygame.HWSURFACE|pygame.DOUBLEBUF|pygame.RESIZABLE, 32)\n",
    "\n",
    "        pygame.display.set_caption(\"Kinect for Windows v2 Body Game\")\n",
    "\n",
    "        # Loop until the user clicks the close button.\n",
    "        self._done = False\n",
    "        self._depth = []\n",
    "        # Used to manage how fast the screen updates\n",
    "        self._clock = pygame.time.Clock()\n",
    "\n",
    "        # Kinect runtime object, we want only color and body and depth frames \n",
    "        self._kinect = PyKinectRuntime.PyKinectRuntime(PyKinectV2.FrameSourceTypes_Depth | \n",
    "                                                       PyKinectV2.FrameSourceTypes_Color | \n",
    "                                                       PyKinectV2.FrameSourceTypes_Body)\n",
    "\n",
    "        # back buffer surface for getting Kinect color frames, 32bit color, width and height equal to the Kinect color frame size\n",
    "        self._frame_surface = pygame.Surface((self._kinect.color_frame_desc.Width, self._kinect.color_frame_desc.Height), 0, 32)\n",
    "        #print(self._frame_surface.get_width())\n",
    "        # here we will store skeleton data \n",
    "        self._bodies = None\n",
    "        \n",
    "        self.Body_keypoints = [] #store all frames keypoints\n",
    "        self.One_frame_points = np.zeros((25,3)) #store a frame keypoints\n",
    "        self.condition_on_points = [PyKinectV2.JointType_Head, PyKinectV2.JointType_Neck,PyKinectV2.JointType_ShoulderRight,\n",
    "                                    PyKinectV2.JointType_ShoulderLeft,PyKinectV2.JointType_SpineMid,PyKinectV2.JointType_ElbowRight\n",
    "                                    ,PyKinectV2.JointType_HipRight,PyKinectV2.JointType_HipLeft,PyKinectV2.JointType_HandRight,\n",
    "                                    PyKinectV2.JointType_ElbowLeft,\n",
    "                                    PyKinectV2.JointType_HandLeft,PyKinectV2.JointType_KneeRight,\n",
    "                                    PyKinectV2.JointType_FootRight,PyKinectV2.JointType_KneeLeft,\n",
    "                                    PyKinectV2.JointType_FootLeft] #check if joint0 or joint1 is in this 15 keypoints\n",
    "        self.joint_depth = []\n",
    "        \n",
    "        self.start_frame = 0\n",
    "        self.end_frame = 42\n",
    "        \n",
    "        self.text = \"\"\n",
    "\n",
    "    \n",
    "    def draw_body_bone(self, joints, jointPoints, color, joint0, joint1):\n",
    "        \n",
    "        joint0State = joints[joint0].TrackingState;\n",
    "        joint1State = joints[joint1].TrackingState;\n",
    "\n",
    "        # both joints are not tracked\n",
    "        if (joint0State == PyKinectV2.TrackingState_NotTracked) or (joint1State == PyKinectV2.TrackingState_NotTracked): \n",
    "            return\n",
    "\n",
    "        # both joints are not *really* tracked\n",
    "        if (joint0State == PyKinectV2.TrackingState_Inferred) and (joint1State == PyKinectV2.TrackingState_Inferred):\n",
    "            return\n",
    "\n",
    "        # ok, at least one is good \n",
    "        if (joint0 in self.condition_on_points) and (self.One_frame_points[joint0].all() == 0):\n",
    "            x = int(self.joint_depth[joint0].x)\n",
    "            y = int(self.joint_depth[joint0].y)\n",
    "            z = int(self._depth[ y * 512 + x ] ) ## Its in Millimeters\n",
    "            self.One_frame_points[joint0] = ([x,y,z])\n",
    "            \n",
    "        if (joint1 in self.condition_on_points) and (self.One_frame_points[joint1].all() == 0):\n",
    "            x = int(self.joint_depth[joint1].x)\n",
    "            y = int(self.joint_depth[joint1].y)\n",
    "            z = int(self._depth[ y * 512 + x ] ) ## Its in Millimeters\n",
    "            self.One_frame_points[joint1] = ([x,y,z])\n",
    "            if joint1 == PyKinectV2.JointType_FootLeft:\n",
    "                self.Body_keypoints.append(self.One_frame_points[[3,2,8,9,11,4,5,7,1,16,17,19,12,13,15]])\n",
    "                self.One_frame_points = np.zeros((25,3)) \n",
    "                print('Body size:',len(self.Body_keypoints))\n",
    "                # model ♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠\n",
    "                if len(self.Body_keypoints) >= 42:\n",
    "                    image = body_to_image(self.Body_keypoints[-42:],self.start_frame,self.end_frame)\n",
    "                    self.start_frame += 42\n",
    "                    self.end_frame += 42\n",
    "                    self.text = test_model(image)\n",
    "                else:\n",
    "                    self.text = \"Nothing\"\n",
    "                #model ♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠♠\n",
    "        \n",
    "        start = (jointPoints[joint0].x, jointPoints[joint0].y)\n",
    "        end = (jointPoints[joint1].x, jointPoints[joint1].y)\n",
    "\n",
    "        try:\n",
    "            pygame.draw.line(self._frame_surface, color, start, end, 8)\n",
    "        except: # need to catch it due to possible invalid positions (with inf)\n",
    "            pass\n",
    "        \n",
    "\n",
    "    def draw_body(self, joints, jointPoints, color):\n",
    "        # Torso\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_Head, PyKinectV2.JointType_Neck);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_Neck, PyKinectV2.JointType_SpineShoulder);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineShoulder, PyKinectV2.JointType_SpineMid);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineMid, PyKinectV2.JointType_SpineBase);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineShoulder, PyKinectV2.JointType_ShoulderRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineShoulder, PyKinectV2.JointType_ShoulderLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineBase, PyKinectV2.JointType_HipRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_SpineBase, PyKinectV2.JointType_HipLeft);\n",
    "    \n",
    "        # Right Arm    \n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_ShoulderRight, PyKinectV2.JointType_ElbowRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_ElbowRight, PyKinectV2.JointType_WristRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_WristRight, PyKinectV2.JointType_HandRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_HandRight, PyKinectV2.JointType_HandTipRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_WristRight, PyKinectV2.JointType_ThumbRight);\n",
    "\n",
    "        # Left Arm\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_ShoulderLeft, PyKinectV2.JointType_ElbowLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_ElbowLeft, PyKinectV2.JointType_WristLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_WristLeft, PyKinectV2.JointType_HandLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_HandLeft, PyKinectV2.JointType_HandTipLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_WristLeft, PyKinectV2.JointType_ThumbLeft);\n",
    "\n",
    "        # Right Leg\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_HipRight, PyKinectV2.JointType_KneeRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_KneeRight, PyKinectV2.JointType_AnkleRight);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_AnkleRight, PyKinectV2.JointType_FootRight);\n",
    "\n",
    "        # Left Leg\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_HipLeft, PyKinectV2.JointType_KneeLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_KneeLeft, PyKinectV2.JointType_AnkleLeft);\n",
    "        self.draw_body_bone(joints, jointPoints, color, PyKinectV2.JointType_AnkleLeft, PyKinectV2.JointType_FootLeft);\n",
    "\n",
    "\n",
    "    def draw_color_frame(self, frame, target_surface):\n",
    "        target_surface.lock()\n",
    "        address = self._kinect.surface_as_array(target_surface.get_buffer())\n",
    "        ctypes.memmove(address, frame.ctypes.data, frame.size)\n",
    "        del address\n",
    "        target_surface.unlock()\n",
    "\n",
    "    def run(self):\n",
    "        global a\n",
    "        # timer\n",
    "        #pygame.time.set_timer(pygame.USEREVENT, 2000)\n",
    "        counter = 0\n",
    "        #limit = 1000\n",
    "        save_img = False\n",
    "        \n",
    "        # -------- Main Program Loop -----------\n",
    "        while not self._done:\n",
    "            # --- Main event loop\n",
    "            for event in pygame.event.get(): # User did something\n",
    "                if event.type == pygame.QUIT: # If user clicked close\n",
    "                    self._done = True # Flag that we are done so we exit this loop\n",
    "\n",
    "                elif event.type == pygame.VIDEORESIZE: # window resized\n",
    "                    self._screen = pygame.display.set_mode(event.dict['size'], \n",
    "                                               pygame.HWSURFACE|pygame.DOUBLEBUF|pygame.RESIZABLE, 32)\n",
    "\n",
    "\n",
    "            if self._kinect.has_new_color_frame():\n",
    "                frame = self._kinect.get_last_color_frame()\n",
    "                self.draw_color_frame(frame, self._frame_surface)\n",
    "                frame = None\n",
    "            \n",
    "            #depth\n",
    "            if self._kinect.has_new_depth_frame():\n",
    "                self._depth = self._kinect.get_last_depth_frame()\n",
    "                \n",
    "            #depth\n",
    "            \n",
    "            # --- Cool! We have a body frame, so can get skeletons\n",
    "            if self._kinect.has_new_body_frame(): \n",
    "                self._bodies = self._kinect.get_last_body_frame()\n",
    "\n",
    "            # --- draw skeletons to _frame_surface\n",
    "            if self._bodies is not None: \n",
    "                for i in range(0, self._kinect.max_body_count):\n",
    "                    body = self._bodies.bodies[i]\n",
    "                    if not body.is_tracked: \n",
    "                        continue \n",
    "                    \n",
    "                    joints = body.joints \n",
    "                    # convert joint coordinates to color space \n",
    "                    joint_points = self._kinect.body_joints_to_color_space(joints)\n",
    "                    self.joint_depth = self._kinect.body_joints_to_depth_space(joints)\n",
    "                    \n",
    "\n",
    "                    self.draw_body(joints, joint_points, SKELETON_COLORS[i])\n",
    "                    \n",
    "\n",
    "                    \n",
    "            # --- copy back buffer surface pixels to the screen, resize it if needed and keep aspect ratio\n",
    "            # --- (screen size may be different from Kinect's color frame size) \n",
    "            h_to_w = float(self._frame_surface.get_height()) / self._frame_surface.get_width()\n",
    "            target_height = int(h_to_w * self._screen.get_width())\n",
    "            surface_to_draw = pygame.transform.scale(self._frame_surface, (self._screen.get_width(), target_height));\n",
    "            self._screen.blit(surface_to_draw, (0,0))\n",
    "            surface_to_draw = None\n",
    "            \n",
    "            #text\n",
    "            font = pygame.font.Font('freesansbold.ttf', 50)\n",
    "            text = font.render('Action:'+self.text, True, pygame.color.THECOLORS[\"red\"], pygame.color.THECOLORS[\"blue\"])\n",
    "            self._screen.blit(text,(0,0))\n",
    "            #text\n",
    "            \n",
    "            pygame.display.update()\n",
    "\n",
    "            # --- Go ahead and update the screen with what we've drawn.\n",
    "            pygame.display.flip()\n",
    "\n",
    "            # --- Limit to 60 frames per second\n",
    "            self._clock.tick(60)\n",
    "\n",
    "        # Close our Kinect sensor, close the window and quit.\n",
    "        a = self.Body_keypoints\n",
    "        self._kinect.close()\n",
    "        pygame.quit()\n",
    "\n",
    "\n",
    "__main__ = \"Kinect v2 Body Game\"\n",
    "game = BodyGameRuntime();\n",
    "game.run();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "game._kinect.close()\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body skeleton used by KARD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Head = 3  \n",
    "# Neck = 2  \n",
    "# Right_Shoulder = 8\n",
    "# Right_Elbow = 9\n",
    "# Right_Hand = 11\n",
    "# Left_Shoulder = 4\n",
    "# Left_Elbow = 5\n",
    "# Left_Hand = 7\n",
    "# Torso = 1\n",
    "# Right_Hip = 16\n",
    "# Right_Knee = 17\n",
    "# Right_Foot = 19 \n",
    "# Left_Hip = 12\n",
    "# Left_Knee = 13\n",
    "# Left_Foot = 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
